{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el0jpI4Cc4Oa"
      },
      "source": [
        "Great source for time series:\n",
        "https://www.machinelearningplus.com/time-series/time-series-analysis-python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw35pYtUpA4E"
      },
      "outputs": [],
      "source": [
        "# Data Source: https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data/notebooks?datasetId=29&sortBy=voteCount"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n66xj4BGKWM"
      },
      "source": [
        "# IMPORT DATASETS AND LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIvlJAxbrTco"
      },
      "outputs": [],
      "source": [
        "#Instalations: #Instalations: \n",
        "\n",
        "!pip install plotly\n",
        "!pip install chart_studio\n",
        "# !pip install prophet\n",
        "!pip install statsmodels\n",
        "!pip3 install --user scipy==1.2.0\n",
        "!pip install statsmodels --upgrade\n",
        "! pip install optuna\n",
        "\n",
        "#After the installation- need to restart the runtime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAdhOkX4jlcp"
      },
      "outputs": [],
      "source": [
        "#restart the runtime so the installation we did above will be refreshed\n",
        "import os\n",
        "\n",
        "def restart_runtime():\n",
        "  os.kill(os.getpid(), 9) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVxYSMIUxx_U"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "\n",
        "#data explanatory and manipulating\n",
        "import pandas as pd\n",
        "from copy import copy\n",
        "import numpy as np\n",
        "# !pip install missingno\n",
        "# import missingno as msno \n",
        "from datetime import date, timedelta,datetime\n",
        "import itertools \n",
        "\n",
        "\n",
        "#Visualization\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import plotly.offline as py\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "#Preperation for model:\n",
        "from pathlib import Path\n",
        "from pylab import rcParams\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Statistical model\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "#Prophet model\n",
        "# from prophet import Prophet\n",
        "# from prophet.plot import add_changepoints_to_plot, plot_forecast_component, plot_yearly\n",
        "# from prophet.diagnostics import cross_validation\n",
        "# from prophet.utilities import regressor_coefficients\n",
        "\n",
        "#DNN model\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, GRU, Bidirectional,Dropout\n",
        "\n",
        "# Random forest:\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "#Hyper parameter tuning:\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") #, category=FutureWarning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKeNql5ZdPa6"
      },
      "outputs": [],
      "source": [
        "# Read the file\n",
        "temperature_df = pd.read_csv('GlobalLandTemperaturesByCountry.csv')\n",
        "\n",
        "# sns.set(style = 'whitegrid')\n",
        "plt.style.use('seaborn-dark')\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.rcParams['font.size'] = '16'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkOi66ogqwTL"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Features:\n",
        "  - dt: Date on which records were observed\n",
        "  - AverageTemperature : Mean temperature of the country \n",
        "  - AverageTemperatureUncertainity: Uncertainty associated with recorded temperature \n",
        "  - Country: Country name\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbCD1xvfAaLN"
      },
      "outputs": [],
      "source": [
        "temperature_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiiUOammsY_U"
      },
      "outputs": [],
      "source": [
        "# Add Dates Columns\n",
        "#Century:\n",
        "temperature_df['Century']=temperature_df['dt'].apply(lambda x: x.split('-')[0]).str[:2]\n",
        "temperature_df['Century']=temperature_df['Century'].astype(int)\n",
        "temperature_df['Century']=temperature_df['Century']+1\n",
        "\n",
        "#year:\n",
        "temperature_df['Year']=temperature_df['dt'].apply(lambda x: x.split('-')[0])\n",
        "temperature_df['Year']=temperature_df['Year'].astype(int)\n",
        "\n",
        "\n",
        "#month:\n",
        "temperature_df['Month']=temperature_df['dt'].apply(lambda x: x.split('-')[1])\n",
        "temperature_df['Month']=temperature_df['Month'].astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z37lPtIMs26o"
      },
      "outputs": [],
      "source": [
        "temperature_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXfsLVbZdPa8"
      },
      "source": [
        "# EXPLORATORY DATA ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txI56ZKndPa9"
      },
      "outputs": [],
      "source": [
        "temperature_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arIQLVhLrLbF"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(temperature_df['AverageTemperature'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLKRKHfJusya"
      },
      "outputs": [],
      "source": [
        "palette = ['tab:blue', 'tab:green', 'tab:orange', 'tab:red']\n",
        "palette = {\n",
        "    18: 'tab:blue',\n",
        "    19: 'tab:purple',\n",
        "    20: 'tab:orange',\n",
        "    21: 'tab:red'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_LLF8YRw-Jk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(data=temperature_df, x='AverageTemperature', hue='Century',palette=palette)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97fgdJ2LxI59"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "ax= sns.barplot(data=temperature_df,x='Century', y='AverageTemperature', palette=palette)\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
        "       ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gxgx36Wrhmu"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(temperature_df['AverageTemperatureUncertainty'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q95aaxwlx7RI"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.rcParams['font.size'] = '16'\n",
        "ax=sns.barplot(data=temperature_df,x='Century', y='AverageTemperatureUncertainty', palette=palette)\n",
        "# ax.set_xlabel('Century', fontsize=16)\n",
        "# ax.set_ylabel('Average Temperature Uncertainty', fontsize=16)\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
        "       ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9Joq7OXyj8q"
      },
      "outputs": [],
      "source": [
        "#WorldWide temperture per month, year, century\n",
        "ww_temp_group_by = temperature_df.groupby([\"Century\",\"Year\", \"Month\"]).mean('AverageTemperature')\n",
        "ww_temp_group_by.reset_index(inplace=True)\n",
        "ww_temp_group_by"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oe_Mo_-06eoh"
      },
      "outputs": [],
      "source": [
        "fig = px.line(ww_temp_group_by,x='Year', y='AverageTemperature', color='Month')\n",
        "fig.update_layout(autosize=False,width=1000,height=500)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1IJZld17QAf"
      },
      "outputs": [],
      "source": [
        "#Animation per month\n",
        "fig = px.line(ww_temp_group_by,x='Year', y='AverageTemperature', color='Month',animation_frame='Month')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBQxjJjXdPbM"
      },
      "outputs": [],
      "source": [
        "# To get the global average tempeature over years\n",
        "df_global = temperature_df.groupby('Year').mean().reset_index()\n",
        "df_global['Year'] = df_global['Year'].apply(lambda x: int(x))\n",
        "\n",
        "# Uncertainity upper bound \n",
        "trace1 = go.Scatter(\n",
        "    x = df_global['Year'], \n",
        "    y = np.array(df_global['AverageTemperature']) + np.array(df_global['AverageTemperatureUncertainty']), # Adding uncertinity\n",
        "    name = 'Uncertainty top',\n",
        "    line = dict(color = 'blue'))\n",
        "\n",
        "# Uncertainity lower bound\n",
        "trace2 = go.Scatter(\n",
        "    x = df_global['Year'] , \n",
        "    y = np.array(df_global['AverageTemperature']) - np.array(df_global['AverageTemperatureUncertainty']), # Subtracting uncertinity\n",
        "    fill = 'tonexty',\n",
        "    name = 'Uncertainty bottom',\n",
        "    line = dict(color = 'blue'))\n",
        "\n",
        "# Recorded temperature\n",
        "trace3 = go.Scatter(\n",
        "    x = df_global['Year'] , \n",
        "    y = df_global['AverageTemperature'],\n",
        "    name = 'Average Temperature',\n",
        "    line = dict(color='purple'))\n",
        "data = [trace1, trace2, trace3]\n",
        "\n",
        "layout = go.Layout(\n",
        "    xaxis = dict(title = 'Year'),\n",
        "    yaxis = dict(title = 'Average Temperature, °C'),\n",
        "    title = 'Average Land Temperatures Globally',\n",
        "    showlegend = False)\n",
        "\n",
        "fig = go.Figure(data = data, layout = layout)\n",
        "fig.update_layout(autosize=False,width=1000,height=500)\n",
        "py.iplot(fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTFHHsHjHzmb"
      },
      "outputs": [],
      "source": [
        "ww_temp_country_count = temperature_df.groupby(\"Year\").count()\n",
        "ww_temp_country_count.reset_index(inplace=True)\n",
        "\n",
        "fig = px.bar(ww_temp_country_count,x='Year', y='Country')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuBKf2IMKj-y"
      },
      "source": [
        "conclusion- I will remove records before 1857 and also 2013 (not fully observed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wMiU1TgL_vp"
      },
      "outputs": [],
      "source": [
        "temperature_df_manipulated =temperature_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "navaJpo9K1HN"
      },
      "outputs": [],
      "source": [
        "# Convert the year to int type and use the data above 1857 for visualization (Before this most of the countries do not have recorded reading)\n",
        "temperature_df_manipulated = temperature_df_manipulated.loc[(temperature_df_manipulated['Year'] > 1857 )&(temperature_df_manipulated['Year'] <2013)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQARRav6LmrQ"
      },
      "outputs": [],
      "source": [
        "temperature_df_manipulated.reset_index(inplace=True,drop=True)\n",
        "temperature_df_manipulated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsKMMn8ZavDh"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "ax1= sns.barplot(data=temperature_df_manipulated,x='Century', y='AverageTemperature', palette=palette)\n",
        "for p in ax1.patches:\n",
        "    ax1.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
        "       ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n",
        "plt.xlabel('Century', fontsize=16)\n",
        "plt.ylabel('Average Temperature', fontsize=16)\n",
        "    \n",
        "plt.figure(figsize=(10,6))\n",
        "ax2=sns.barplot(data=temperature_df_manipulated,x='Century', y='AverageTemperatureUncertainty', palette=palette)\n",
        "for p in ax2.patches:\n",
        "    ax2.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
        "       ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n",
        "plt.xlabel('Century', fontsize=16)\n",
        "plt.ylabel('Average Temperature Uncertainty', fontsize=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWPB_O0S7yzw"
      },
      "outputs": [],
      "source": [
        "# To get the global average tempeature over years\n",
        "df_global = temperature_df_manipulated.groupby('Year').mean().reset_index()\n",
        "df_global['Year'] = df_global['Year'].apply(lambda x: int(x))\n",
        "\n",
        "# Uncertainity upper bound \n",
        "trace1 = go.Scatter(\n",
        "    x = df_global['Year'], \n",
        "    y = np.array(df_global['AverageTemperature']) + np.array(df_global['AverageTemperatureUncertainty']), # Adding uncertinity\n",
        "    name = 'Uncertainty top',\n",
        "    line = dict(color = 'blue'))\n",
        "\n",
        "# Uncertainity lower bound\n",
        "trace2 = go.Scatter(\n",
        "    x = df_global['Year'] , \n",
        "    y = np.array(df_global['AverageTemperature']) - np.array(df_global['AverageTemperatureUncertainty']), # Subtracting uncertinity\n",
        "    fill = 'tonexty',\n",
        "    name = 'Uncertainty bottom',\n",
        "    line = dict(color = 'blue'))\n",
        "\n",
        "# Recorded temperature\n",
        "trace3 = go.Scatter(\n",
        "    x = df_global['Year'] , \n",
        "    y = df_global['AverageTemperature'],\n",
        "    name = 'Average Temperature',\n",
        "    line = dict(color='purple'))\n",
        "data = [trace1, trace2, trace3]\n",
        "\n",
        "layout = go.Layout(\n",
        "    xaxis = dict(title = 'Year'),\n",
        "    yaxis = dict(title = 'Average Temperature, °C'),\n",
        "    title = 'Average Land Temperatures Globally',\n",
        "    showlegend = False)\n",
        "\n",
        "fig = go.Figure(data = data, layout = layout)\n",
        "py.iplot(fig)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjIofwItdPa9"
      },
      "source": [
        "# DATA MANIPULATION:\n",
        "\n",
        "\n",
        "1.   Remove duplications in countries\n",
        "2.   Remove countries with only few datapoints\n",
        "3.   data imputation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLhCgQEDf0EE"
      },
      "source": [
        "Remove duplications:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P33awYLPAKF1"
      },
      "outputs": [],
      "source": [
        "temperature_df_full=temperature_df_manipulated.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0H28zpX7H0P"
      },
      "outputs": [],
      "source": [
        "temperature_df_full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VkjJ29ldPa8"
      },
      "outputs": [],
      "source": [
        "# Check the unique countries\n",
        "temperature_df_manipulated['Country'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4USBd1QNrHGW"
      },
      "outputs": [],
      "source": [
        "#Unify countries that has the same name, for example: 'United Kingdom (Europe)' & 'United Kingdom'\n",
        "duplicates=temperature_df_manipulated[temperature_df_manipulated['Country'].str.contains('(',regex=False)]#regex=False because we are searching for '(' value. otherwise it will raise an error\n",
        "duplicates=duplicates['Country'] #DataFrame\n",
        "duplicates=duplicates.unique() #to get a list of the duplicates countries \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kiF9aIymsB1"
      },
      "outputs": [],
      "source": [
        "for i in duplicates:\n",
        "  num=i.find(' (')\n",
        "  print(i,num)\n",
        "  temperature_df_manipulated.replace(i,i[0:num], inplace=True) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wAxWo3UosQX"
      },
      "outputs": [],
      "source": [
        "#Check that there is no duplicated\n",
        "duplicates=temperature_df_manipulated[temperature_df_manipulated['Country'].str.contains('(',regex=False)]#regex=False because we are searching for '(' value. otherwise it will raise an error\n",
        "duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7lV41uddPa9"
      },
      "outputs": [],
      "source": [
        "# Do groupby country to see the count of values available for each country\n",
        "country_group_df = temperature_df_manipulated.groupby(by = 'Country').count().reset_index('Country').rename(columns={'AverageTemperature':'AverageTemperatureCount','AverageTemperatureUncertainty' : 'AverageTemperatureUncertaintyCount'})\n",
        "country_group_df=country_group_df.sort_values(by='AverageTemperatureCount')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkvMGGwbdPa_"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(country_group_df, x = 'Country', y = 'AverageTemperatureCount', title=\"number of records per country\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flizqPPGf-DW"
      },
      "source": [
        "Remove countries with only few datapoints (less then 15% (6332*0.15= 950))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dry2s8c1kymb"
      },
      "outputs": [],
      "source": [
        "# missing_records_threshold=950"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11KCazNXdPbB"
      },
      "outputs": [],
      "source": [
        "# countries_with_less_data=country_group_df[(country_group_df['AverageTemperatureCount'] < missing_records_threshold) | (country_group_df['AverageTemperatureUncertaintyCount'] < missing_records_threshold)]\n",
        "# countries_with_less_data=countries_with_less_data.Country.tolist()\n",
        "\n",
        "# countries_with_less_data\n",
        "\n",
        "countries_with_less_data = country_group_df[(country_group_df['AverageTemperatureCount'] < 1300) | (country_group_df['AverageTemperatureUncertaintyCount'] < 1300)]\n",
        "countries_with_less_data=countries_with_less_data['Country'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aowr_iJx3h1a"
      },
      "outputs": [],
      "source": [
        "countries_with_less_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3nh5NlYdPbC"
      },
      "outputs": [],
      "source": [
        "# Remove the countries with less data points\n",
        "temperature_df_manipulated = temperature_df_manipulated[~temperature_df_manipulated['Country'].isin(countries_with_less_data)]\n",
        "# Reset the index\n",
        "temperature_df_manipulated.reset_index(inplace = True, drop = True)\n",
        "temperature_df_manipulated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL_U-NJvYq0B"
      },
      "source": [
        "# Data Imputation:\n",
        "\n",
        "Fill the missing values by doing rolling average per country and monthin the past 20 years\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpylQXqWdPa8"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "temperature_df_manipulated.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1w_T-kxxdPbD"
      },
      "outputs": [],
      "source": [
        "#Option #1:Fill the missing values by doing rolling average per country and monthin the past 20 years\n",
        "# temperature_df_manipulated['MA'] = temperature_df_manipulated.groupby(['Country','Month']).AverageTemperature.transform(lambda x: x.rolling(20,min_periods=1).mean())\n",
        "# temperature_df_manipulated['MA2'] = temperature_df_manipulated.groupby(['Country','Month']).AverageTemperatureUncertainty.transform(lambda x: x.rolling(20,min_periods=1).mean())\n",
        "\n",
        "# temperature_df_manipulated.AverageTemperature.fillna(temperature_df_manipulated.MA, inplace=True)\n",
        "# temperature_df_manipulated.AverageTemperatureUncertainty.fillna(temperature_df_manipulated.MA2, inplace=True)\n",
        "\n",
        "# del temperature_df_manipulated['MA']\n",
        "# del temperature_df_manipulated['MA2']\n",
        "\n",
        "# temperature_df_manipulated\n",
        "\n",
        "#Option #2: Fill the missing values by doing rolling average on past 730 months\n",
        "temperature_df_manipulated['AverageTemperature'] = temperature_df_manipulated['AverageTemperature'].fillna(temperature_df_manipulated['AverageTemperature'].rolling(240, min_periods = 1).mean())\n",
        "temperature_df_manipulated['AverageTemperatureUncertainty']= temperature_df_manipulated['AverageTemperatureUncertainty'].fillna(temperature_df_manipulated['AverageTemperatureUncertainty'].rolling(240, min_periods=1).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ep_S3RiydPbD"
      },
      "outputs": [],
      "source": [
        "temperature_df_manipulated.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cprPbihH-gdN"
      },
      "outputs": [],
      "source": [
        "#Drop null records after imputation\n",
        "# temperature_df=temperature_df[~temperature_df['AverageTemperature'].isnull()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nFC4pHcGr57"
      },
      "source": [
        "# DATA VISUALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onwN8ky494An"
      },
      "outputs": [],
      "source": [
        "countries = temperature_df_manipulated['Country'].unique().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtLpjgcHdPbH"
      },
      "outputs": [],
      "source": [
        "# Get the mean temperature for each country\n",
        "mean_temperature = []\n",
        "for i in countries:\n",
        "    mean_temperature.append(temperature_df_manipulated[temperature_df_manipulated['Country'] == i]['AverageTemperature'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDRjvXrjdPbH"
      },
      "outputs": [],
      "source": [
        "# Plot the mean teamperature of countries\n",
        "data = [ dict(type = 'choropleth', # type of map\n",
        "              locations = countries, # location names\n",
        "              z = mean_temperature, # temperature of countries\n",
        "              locationmode = 'country names')\n",
        "       ]\n",
        "\n",
        "layout = dict(title = 'Average Global Land Temperatures',\n",
        "              geo = dict(showframe = False,\n",
        "                         showocean = True, # to show the ocean\n",
        "                         oceancolor = '#3399FF',\n",
        "                         projection = dict(type = 'orthographic'))) # to get the globe view),\n",
        "\n",
        "\n",
        "fig = dict(data = data, layout = layout)\n",
        "py.iplot(fig, validate = False, filename = 'worldmap')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xW-ABe5I4gDQ"
      },
      "outputs": [],
      "source": [
        "temperature_df_manipulated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Evy6iJuA9bhE"
      },
      "source": [
        "Indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtFAzddXpA5z"
      },
      "outputs": [],
      "source": [
        "# To get the global average tempeature over years\n",
        "df_global_monthly = temperature_df_manipulated.groupby(['dt']).mean().reset_index()\n",
        "# df_global_monthly=df_global_monthly.drop(['Century','Year'],axis=1)\n",
        "df_global_monthly=df_global_monthly.drop(['Century','Year'],axis=1).set_index('dt')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uU_EdDL7yRwl"
      },
      "outputs": [],
      "source": [
        "date_index = pd.to_datetime(df_global_monthly.index)\n",
        "date_index = pd.DatetimeIndex(date_index.values, freq = date_index.inferred_freq)\n",
        "infered_freq=date_index.inferred_freq\n",
        "print(\"freq:\",date_index.freq)\n",
        "print(\"infered freq:\",date_index.inferred_freq)\n",
        "print(date_index)\n",
        "infered_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxoYdfYoz6NL"
      },
      "outputs": [],
      "source": [
        "df_global_monthly.index.astype(date_index)\n",
        "# df_global_monthly.index.freq = df_global_monthly.index.freq.apply(lambda x: infered_freq if x == 'None'  else df_global_monthly.index.freq)\n",
        "# df_global_monthly=df_global_monthly.drop('AverageTemperatureUncertainty',axis=1)\n",
        "# print (df_global_monthly.index.freq)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zc0pYgapyRB"
      },
      "outputs": [],
      "source": [
        "df_for_arima=df_global_monthly.copy()\n",
        "df_for_arima=df_for_arima.drop(['AverageTemperatureUncertainty','Month'],axis=1)\n",
        "df_for_arima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkzOUZxx49KF"
      },
      "outputs": [],
      "source": [
        "rcParams['figure.figsize'] = 18, 8\n",
        "decomposition = sm.tsa.seasonal_decompose(df_for_arima.asfreq(infered_freq) ,model='additive') #infered_freq in this case- 'MS' (Month start)\n",
        "fig = decomposition.plot()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g14rbCpfFkZv"
      },
      "outputs": [],
      "source": [
        "print(decomposition.seasonal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQ0Cl6cmrIG8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpBPZ-na5jjo"
      },
      "source": [
        "#Define the DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah13FC715r-r"
      },
      "outputs": [],
      "source": [
        "df_global_monthly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTzXHIKTYxpO"
      },
      "source": [
        "# Stationary check- pre preperations before time-series models:\n",
        "Will be checked according to ADF test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4JfThRgZMfo"
      },
      "outputs": [],
      "source": [
        "# statistic test (ADF) to check to stationary hypothesis\n",
        "'''\n",
        "if The p-value is greater than significance level of 0.05 or 0.01 (what we choose) \n",
        "and the ADF statistic is higher than any of the critical values, WE ARE NOT rejecting\n",
        "the null hypothesis (HO) which means, the time series is in fact non-stationary.\n",
        "\n",
        "to summarize: \n",
        "if ADF statistic > critical value --> we DO NOT reject HO -->The data is not stationary\n",
        "if ADF statistic < critical value --> we DO reject HO --> The data is stationary\n",
        "\n",
        "If reject HO=False- The data is not stationary\n",
        "If reject HO=True- The data is stationary\n",
        "'''\n",
        "\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import math\n",
        "\n",
        "def ADF_Cal(x):\n",
        "    result = adfuller(x)\n",
        "    ADF_stat = result[0]\n",
        "    print(\"adf\",ADF_stat )\n",
        "    p = result[1]\n",
        "    if math.isnan(p):\n",
        "      ADF_stat=0\n",
        "      p=0\n",
        "    print(\"ADF Statistic: %f\" % ADF_stat)\n",
        "    print(\"p-value: %f\" % p)\n",
        "    print(\"Critical Values\")\n",
        "    levels = [.01, .05, .1]\n",
        "    i = 0\n",
        "    for key,value in result[4].items():\n",
        "        print('\\t%s: %.3f' % (key,value))\n",
        "        hyp = p < levels[i]\n",
        "        if ADF_stat < value:\n",
        "            cert = (1-levels[i])*100\n",
        "            print(\"{}% certain this is staionary\".format(cert))\n",
        "            print('Reject H0: {}'.format(hyp))\n",
        "            break\n",
        "        i = i+1\n",
        "        if i >= 3:\n",
        "            print(\"Less than 90% certain that data is stationary\")\n",
        "            print('Reject H0: {}'.format(hyp))\n",
        "    return hyp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd8BsgAsaTeA"
      },
      "outputs": [],
      "source": [
        "#Need to check only one numerical column\n",
        "#AverageTemperature column\n",
        "to_check1=df_global_monthly['AverageTemperature']\n",
        "#AverageTemperatureUncertainty column\n",
        "# to_check2=df_global_monthly['AverageTemperatureUncertainty']\n",
        "\n",
        "print('ADF test for AverageTemperature column: ')\n",
        "hyp=ADF_Cal(to_check1)\n",
        "# print('\\n\\nADF test for AverageTemperatureUncertainty column: ')\n",
        "# hyp=ADF_Cal(to_check2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mUvWelMbLlg"
      },
      "source": [
        "Conclusion- data is not stationary.\n",
        "need to transform the data (can be done by Difference Transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTtR2CPOKH7_"
      },
      "outputs": [],
      "source": [
        "year_df=df_global_monthly.copy()\n",
        "year_df['dt']=year_df.index\n",
        "year_df['Year']=year_df['dt'].apply(lambda x: x.split('-')[0])\n",
        "year_df_grouped=year_df.groupby('Year').mean()\n",
        "year_df_grouped=year_df_grouped['AverageTemperature']\n",
        "year_df_grouped\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeYa1RTzMmIu"
      },
      "outputs": [],
      "source": [
        "plt.plot(year_df_grouped)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGBFUwEfpA5z"
      },
      "source": [
        "# PERPARE THE DATA TO TRAIN THE MODEL\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR8hj0RSuPVe"
      },
      "source": [
        "#Train- Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4aEQk0H6Xg0"
      },
      "outputs": [],
      "source": [
        "train_split=0.9\n",
        "val_size=0.2\n",
        "\n",
        "# # Split the data\n",
        "# train = df_global_monthly[:int(0.9 * len(df_global_monthly))].drop(columns = 'dt').values\n",
        "# test = df_global_monthly[int(0.9 * len(df_global_monthly)):].drop(columns = 'dt').values\n",
        "# train,val=train_test_split(train,test_size=0.2,shuffle=False)\n",
        "train = df_global_monthly[:int(train_split * len(df_global_monthly))]\n",
        "test = df_global_monthly[int(train_split * len(df_global_monthly)):]\n",
        "\n",
        "#for Arima model:\n",
        "train_arima = df_for_arima[:int(train_split * len(df_for_arima))]\n",
        "test_arima = df_for_arima[int(train_split * len(df_for_arima)):]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ry_5_d4Om5De"
      },
      "outputs": [],
      "source": [
        "last_train_value=train.iloc[-1,0]\n",
        "last_train_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIjvTmSfQCTt"
      },
      "outputs": [],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKIWLAmvHkXE"
      },
      "outputs": [],
      "source": [
        "a=df_global_monthly.copy()\n",
        "a['rolling_avg']=a['AverageTemperature'].rolling( 12).mean()\n",
        "\n",
        "# Plot train and test data\n",
        "fig=plt.figure(figsize = (18, 12))\n",
        "ax=plt.plot(train.AverageTemperature,color='purple')\n",
        "# ax=plt.plot(val.Target,color='pink')\n",
        "ax= plt.plot(test.AverageTemperature,color='blue')\n",
        "plt.ylabel('Average Temperature')\n",
        "plt.legend(['Train set','validation set', 'Test set'], loc='lower right',fontsize=22)\n",
        "\n",
        "\n",
        "# plot using rolling average\n",
        "sns.lineplot( x = a.index,\n",
        "             y = 'rolling_avg',\n",
        "             data = a,\n",
        "             label = 'Rollingavg',\n",
        "             color='black',\n",
        "             linewidth=2.5)\n",
        "\n",
        "print('Dimension of train data: ',train.shape)\n",
        "# print('Dimension of validation data: ',val.shape)\n",
        "print('Dimension of test data: ', test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_2-HrxE6Xg0"
      },
      "source": [
        "#Create 'Lagged' Data Frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOIRn4Y1_1qE"
      },
      "outputs": [],
      "source": [
        "# Function that creates the data for training the time series model\n",
        "def prepare_data(df, num_of_lag_differences): #,seasonal_cycle\n",
        "    # Get the columns\n",
        "    column_name = 'AverageTemperature'\n",
        "    # For the given range, create lagged input feature for the given columns\n",
        "    for i in range(( num_of_lag_differences ),0, -1):\n",
        "      name =column_name + '_t-' + str(i)\n",
        "      df[name] = df[column_name].shift((i)) \n",
        "    # Create the target by using next value as the target\n",
        "    df['Target'] = df['AverageTemperature']\n",
        "    return df\n",
        "\n",
        "num_of_lag_differences=12\n",
        "# Get the training data\n",
        "train = prepare_data(train, num_of_lag_differences)\n",
        "train = train.dropna()\n",
        "train=train.drop(['AverageTemperature'],axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nDvcWgCgc0T"
      },
      "outputs": [],
      "source": [
        "train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azX8MOu6sG5E"
      },
      "source": [
        "#Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktv5FFkV6Xg1"
      },
      "outputs": [],
      "source": [
        "# Scale the data\n",
        "scaler = MinMaxScaler(feature_range = (0, 1))\n",
        "train_sc  = scaler.fit_transform(train)\n",
        "# # val_sc  = scaler.transform(val)\n",
        "# test   = scaler.transform(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrFm3Ndx6Xg1"
      },
      "outputs": [],
      "source": [
        "# # Split the data into input features and targets\n",
        "# #All features:\n",
        "# train_x, train_y = train_sc[:,:-1], train_sc[:,-1] #train data is already scaled- this it's Numpy array and not dataFrame\n",
        "# # val_x, val_y = val_sc[:,:-1], val_sc[:,-1]  # VAL data is already scaled- this it's Numpy array and not dataFrame\n",
        "# test_x, test_y = test.iloc[:,1:], test.iloc[:,0] # I'm using iloc because the test data is still un-scaled dataFrame. the Y value in this DF is at location 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVjNlriuEb0A"
      },
      "source": [
        "Blocking Time Series Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkjKsp72Eaep"
      },
      "outputs": [],
      "source": [
        "#Cross validation method in time series- Blocking Time Series Split\n",
        "class BlockingTimeSeriesSplit():\n",
        "    def __init__(self, n_splits):\n",
        "        self.n_splits = n_splits\n",
        "    \n",
        "    def get_n_splits(self, X, y, groups):\n",
        "        return self.n_splits\n",
        "    \n",
        "    def split(self, X, y=None, groups=None):\n",
        "        n_samples = len(X)\n",
        "        k_fold_size = n_samples // self.n_splits\n",
        "        indices = np.arange(n_samples)\n",
        "        split_ratio=0.8\n",
        "\n",
        "        margin = 0\n",
        "        for i in range(self.n_splits):\n",
        "            start = i * k_fold_size\n",
        "            stop = start + k_fold_size\n",
        "            split = int(split_ratio * (stop - start)) + start\n",
        "            yield i,indices[start: split], indices[split + margin: stop]\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYZZfa6jG1Fr"
      },
      "outputs": [],
      "source": [
        "def plot_cv_indices(cv, X, ax, n_splits, lw=10):\n",
        "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
        "\n",
        "    # Generate the training/testing visualizations for each CV split\n",
        "    for ii, (subset,tr, tt) in enumerate(cv.split(X=X,  groups=None)):\n",
        "        # Fill in indices with the training/test groups\n",
        "        indices = np.array([np.nan] * len(X))\n",
        "        indices[tt] = 1\n",
        "        indices[tr] = 0\n",
        "\n",
        "        # Visualize the results\n",
        "        ax.scatter(range(len(indices)), [ii] * len(indices),\n",
        "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
        "                   vmin=-.2, vmax=1.2)\n",
        "        \n",
        "    # Plot the data classes and groups at the end\n",
        "    ax.scatter(range(len(X)), [ii + 1] * len(X),\n",
        "               c=y, marker='_', lw=lw, cmap=cmap_data)\n",
        "\n",
        "    # Formatting\n",
        "    yticklabels = list(range(n_splits)) + ['class']\n",
        "    ax.set(yticks=np.arange(n_splits+2), yticklabels=yticklabels,\n",
        "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
        "           ylim=[n_splits+1.2, -.1], xlim=[0, 100])\n",
        "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FiUMVIpEhGU"
      },
      "outputs": [],
      "source": [
        "from matplotlib.patches import Patch\n",
        "cmap_cv = plt.cm.coolwarm\n",
        "cmap_data=0\n",
        "\n",
        "n_splits=5\n",
        "tscv = BlockingTimeSeriesSplit(n_splits=n_splits)\n",
        "fig, ax = plt.subplots(figsize=(10, 5))  \n",
        "ax.legend([Patch(color=cmap_cv(.8)), Patch(color=cmap_cv(.02))],\n",
        "         ['validation set', 'Training set'], loc=(1.02, .8))\n",
        "plt.tight_layout()\n",
        "plt.xlabel('Sample index')\n",
        "plt.title('Blocking Time Series Split')\n",
        "fig.subplots_adjust(right=.7)    \n",
        "# plot_cv_indices(tscv, train, ax, n_splits) \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYttDRBepA52"
      },
      "source": [
        "# BUILD AND TRAIN RNN AND LSTM MODELS FOR PREDICTING GLOBAL TEMPERATURE TREND"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIqyM3U8OXIQ"
      },
      "source": [
        "**Reshape to 3D input dataset:**\n",
        "LSTM, GRU and BiLSTM take a 3D input (num_samples, num_timesteps, num_features). I have create a helper function, 'prepaere data' and another function: \"Reshape data set\"  to reshape input.\n",
        "In this project, I define time_steps =12 for the **prepare data'** function. It means that the dataset makes 12 new features of previous 12 months average temperature.\n",
        "\n",
        "because of this pre-processing stage- i donr need to define to tensor any orhe time-stamp but 1, therefor, in the **\"reshape_data_set\"** function i will set timestamp to be 1 because in the data set i have prepared i have already representation of the last 12 previous values (as features).\n",
        "\n",
        "if i had skipped the **prepare data'** function, i didnt have representation of the last 12 months so i have to reshape the data to the tensor to be:\n",
        "(num of samples/12,12,num of features (1 for univarialte model))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTBXvW6SJQ5W"
      },
      "outputs": [],
      "source": [
        "def reshape_data_sets(*args): #must be np.array\n",
        "  for i in args:\n",
        "    a=i.reshape((i.shape[0], 1, i.shape[1]))\n",
        "    return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXrKNTV3-2to"
      },
      "outputs": [],
      "source": [
        "# #reshape: (sample size,time_stamp (see explanation above), features)\n",
        "# train_x_rs,val_x_rs=reshape_data_sets(train_x,val_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgVzsIHfSHES"
      },
      "outputs": [],
      "source": [
        "# train_x_rs=train_x.reshape((train_x.shape[0], 1, train_x.shape[1]))\n",
        "# # val_x_rs=val_x.reshape((val_x.shape[0], 1, val_x.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYvBrUnZSq4_"
      },
      "outputs": [],
      "source": [
        "# train_x_rs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTnjudnZEI92"
      },
      "outputs": [],
      "source": [
        "def customLoss(y_true, y_pred):\n",
        "  loss=tf.math.divide_no_nan(tf.abs(y_true-y_pred),y_true)\n",
        "  return tf.reduce_mean(loss)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oko806ifDAk3"
      },
      "source": [
        "Create models, train and fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBrfXSSusAHG"
      },
      "source": [
        "### ARIMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uS823hKcuF1z"
      },
      "outputs": [],
      "source": [
        "train_arima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCAg1nvPKfTD"
      },
      "outputs": [],
      "source": [
        "arima_model = sm.tsa.statespace.SARIMAX(train_arima.asfreq(infered_freq),\n",
        "                                order=(1, 1, 1),\n",
        "                                seasonal_order=(1, 1, 0, 12),\n",
        "                                enforce_stationarity=False,\n",
        "                                enforce_invertibility=False)\n",
        "\n",
        "arima_results = arima_model.fit()\n",
        "\n",
        "print(arima_results.summary().tables[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjFn0pPGGGFu"
      },
      "outputs": [],
      "source": [
        "arima_results.plot_diagnostics(figsize=(15, 12))\n",
        "plt.show()\n",
        "\n",
        "#interpatations: https://www.digitalocean.com/community/tutorials/a-guide-to-time-series-forecasting-with-arima-in-python-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKCoQtLyurin"
      },
      "outputs": [],
      "source": [
        "test_arima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAjne0x4ulzs"
      },
      "outputs": [],
      "source": [
        "start_test_data=test_arima.index[0]\n",
        "start_test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DWEqEpwGK9S"
      },
      "outputs": [],
      "source": [
        "pred = arima_results.get_prediction(start=pd.to_datetime(start_test_data), dynamic=False)\n",
        "pred_ci = pred.conf_int()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rpjDNETPLV5"
      },
      "outputs": [],
      "source": [
        "df_for_arima_new=df_for_arima.merge(pred_ci,left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySnsOgI8v2Ez"
      },
      "outputs": [],
      "source": [
        "df_for_arima_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2avv763Rx9E"
      },
      "outputs": [],
      "source": [
        "df_for_arima.index=df_for_arima.index.astype(date_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8o9n1CYRg4A"
      },
      "outputs": [],
      "source": [
        "df_for_arima_new=pd.concat([df_for_arima, pred_ci], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irduDLMPPgOU"
      },
      "outputs": [],
      "source": [
        "df_for_arima_new['Average prediction']= df_for_arima_new.iloc[:,1:3].mean(axis=1)\n",
        "df_for_arima_new['dt']=df_for_arima_new.index\n",
        " # Calculate the error \n",
        "df_for_arima_new['Error'] = np.abs(df_for_arima_new['AverageTemperature'] - df_for_arima_new['Average prediction'])\n",
        "df_for_arima_new['APE']=(df_for_arima_new['Error']/df_for_arima_new['AverageTemperature'])*100\n",
        "df_for_arima_new\n",
        "\n",
        "MAPE_arima=np.mean(df_for_arima_new['APE'])\n",
        "\n",
        "  # pred['dt'] = df.index[-test_x.shape[0]:]\n",
        "  # # Calculate the error \n",
        "  # pred['Error'] = np.abs(pred['Original'] - pred['Predicted'])\n",
        "  # pred['APE']=pred['Error']/pred['Original']*100\n",
        "        \n",
        "  # # Create dataframe for visualization\n",
        "  # df_new=df.copy()\n",
        "  # df_new['dt']=df_new.index #Bring back the 'dt' to the dataframe\n",
        "  # df_new = df_new[['dt','Target']][:-test_x.shape[0]]\n",
        "  # df_new.columns = ['dt','Original']\n",
        "  # original = df_new.append(pred[['dt','Original']])\n",
        "  # df_new.columns = ['dt','Predicted']\n",
        "  # predicted = df_new.append(pred[['dt','Predicted']])\n",
        "  # original = original.merge(predicted, left_on = 'dt',right_on = 'dt')\n",
        "\n",
        "  # MAPE=np.mean(pred['APE'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsMpvivYygv3"
      },
      "outputs": [],
      "source": [
        "accuracy_arima=100-MAPE_arima\n",
        "accuracy_arima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FstHIvNA6JGh"
      },
      "outputs": [],
      "source": [
        "df_for_arima_new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9cN7DEdfkew"
      },
      "source": [
        "#RNN'S"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kl56BDhHCpS"
      },
      "outputs": [],
      "source": [
        "dropout=0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlmZrADekh11"
      },
      "outputs": [],
      "source": [
        "def create_shallow_RNN_model(train_x_rs,val_x_rs,hidden_units,optimizer,epochs,batchsize): #dropout,,activation1,activation2\n",
        "    # Create the model\n",
        "    inputs = keras.layers.Input(shape = (train_x_rs.shape[1], train_x_rs.shape[2]))\n",
        "    x = keras.layers.SimpleRNN(hidden_units)(inputs)\n",
        "    # x = keras.layers.Dropout(0.3)(x)\n",
        "    # x = keras.layers.SimpleRNN(hidden_units,return_sequences = True)(x)\n",
        "    # x = keras.layers.Dropout(0.3)(x)\n",
        "    # x = keras.layers.SimpleRNN(hidden_units)(x)\n",
        "    outputs = keras.layers.Dense(1, activation = 'linear')(x)\n",
        "\n",
        "    model_shallow_rnn = keras.Model(inputs = inputs, outputs = outputs)\n",
        "    model_shallow_rnn.compile(optimizer=optimizer,loss=customLoss,metrics=['mean_absolute_percentage_error'])\n",
        "\n",
        "    history = model_shallow_rnn.fit(train_x_rs, train_y,\n",
        "                    epochs=epochs,\n",
        "                    verbose=0,\n",
        "                    validation_data=(val_x_rs, val_y),\n",
        "                    batch_size=batchsize)\n",
        "\n",
        "    return history,model_shallow_rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQE8L6eYW79X"
      },
      "outputs": [],
      "source": [
        "def create_RNN_model(train_x_rs,val_x_rs,hidden_units,optimizer,epochs,batchsize): #dropout,,activation1,activation2\n",
        "    # Create the model\n",
        "    inputs = keras.layers.Input(shape = (train_x_rs.shape[1], train_x_rs.shape[2]))\n",
        "    x = keras.layers.SimpleRNN(hidden_units,return_sequences =  True)(inputs)\n",
        "    x = keras.layers.Dropout(0.3)(x)\n",
        "    x = keras.layers.SimpleRNN(hidden_units,return_sequences = True)(x)\n",
        "    x = keras.layers.Dropout(0.3)(x)\n",
        "    x = keras.layers.SimpleRNN(hidden_units)(x)\n",
        "    outputs = keras.layers.Dense(1, activation = 'linear')(x)\n",
        "\n",
        "    model_rnn = keras.Model(inputs = inputs, outputs = outputs)\n",
        "    model_rnn.compile(optimizer=optimizer,loss=customLoss,metrics=['mean_absolute_percentage_error'])\n",
        "\n",
        "    history = model_rnn.fit(train_x_rs, train_y,\n",
        "                    epochs=epochs,\n",
        "                    verbose=0,\n",
        "                    validation_data=(val_x_rs, val_y),\n",
        "                    batch_size=batchsize)\n",
        "\n",
        "    return history,model_rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdARDaviWQRA"
      },
      "outputs": [],
      "source": [
        "def create_LSTM_model(train_x_rs,val_x_rs,hidden_units,optimizer,epochs,batchsize): #dropout,,activation1,activation2\n",
        "    # Create the model\n",
        "    inputs = keras.layers.Input(shape = (train_x_rs.shape[1], train_x_rs.shape[2]))\n",
        "    x = keras.layers.LSTM(hidden_units,return_sequences =  True)(inputs)\n",
        "    x = keras.layers.Dropout(0.3)(x)\n",
        "    x = keras.layers.LSTM(hidden_units, return_sequences = True)(x)\n",
        "    x = keras.layers.Dropout(0.3)(x)\n",
        "    x = keras.layers.LSTM(hidden_units)(x)\n",
        "    outputs = keras.layers.Dense(1, activation = 'linear')(x)\n",
        "\n",
        "    model_lstm = keras.Model(inputs = inputs, outputs = outputs)\n",
        "    model_lstm.compile(optimizer=optimizer,loss=customLoss,metrics=['mean_absolute_percentage_error'])\n",
        "\n",
        "    history = model_lstm.fit(train_x_rs, train_y,\n",
        "                    epochs=epochs,\n",
        "                    verbose=0,\n",
        "                    validation_data=(val_x_rs, val_y),\n",
        "                    batch_size=batchsize)\n",
        "\n",
        "    return history,model_lstm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y2Ggw4hRlLt"
      },
      "source": [
        "choose randomally hyper parameters for RNN and LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEmmIIIQytkv"
      },
      "outputs": [],
      "source": [
        "hidden_units=5\n",
        "optimizer='adam'\n",
        "epochs=100\n",
        "batchsize=10\n",
        "\n",
        "tscv = BlockingTimeSeriesSplit(n_splits)\n",
        "scores_shallow_rnn=[]\n",
        "scores_rnn = []\n",
        "scores_lstm = []\n",
        "\n",
        "#get the block-time-series single fold indices\n",
        "for sub_set,train_index, val_index in tscv.split(train_sc):\n",
        "  # print(\"\\n\\nsub_set:\", sub_set,\"\\nTRAIN:\\n\", train_index, \"\\nval:\\n\", val_index)\n",
        "\n",
        "  #subset the scaled train set into rtain and validation according to indeices we got from the prev. step\n",
        "  train_x = train_sc[train_index,:-1]\n",
        "  val_x = train_sc[val_index,:-1]\n",
        "  train_y = train_sc[train_index,-1]\n",
        "  val_y = train_sc[val_index,-1]\n",
        "  print (train_x.shape[0],1,train_x.shape[1])\n",
        "  print (val_x.shape[0],1,val_x.shape[1])\n",
        "\n",
        "  # #reshape: (sample size,time_stamp (see explanation above), features)\n",
        "  train_x_rs=train_x.reshape(train_x.shape[0],1,train_x.shape[1])\n",
        "  val_x_rs=val_x.reshape(val_x.shape[0],1,val_x.shape[1])\n",
        "  \n",
        "\n",
        "  #get the block-time-series single fold indices\n",
        "for sub_set,train_index, val_index in tscv.split(train_sc):\n",
        "  print (\"Fold #\",sub_set+1)\n",
        " \n",
        "  #RNN\n",
        "  history_rnn,model_RNN = create_RNN_model(train_x_rs,val_x_rs,hidden_units=hidden_units,optimizer=optimizer,epochs=epochs,batchsize=batchsize)\n",
        "  val_rnn_score=100-history_rnn.history['val_loss'][-1]\n",
        "  # print('MAPE DEEP RNN:  ',history_rnn.history['val_loss'][-1])\n",
        "  scores_rnn.append(val_rnn_score)\n",
        "\n",
        "  #LSTM\n",
        "  history_lstm,model_LSTM = create_LSTM_model(train_x_rs,val_x_rs,hidden_units=hidden_units,optimizer=optimizer,epochs=epochs,batchsize=batchsize)\n",
        "  # print('MAPE DEEP LSTM:  ',history_lstm.history['val_loss'][-1])\n",
        "  val_lstm_score=100-history_lstm.history['val_loss'][-1]\n",
        "  scores_lstm.append(val_lstm_score)\n",
        "\n",
        "print('Scores from each Iteration- Deep RNN: {}\\n Scores from each Iteration- Deep LSTM: {}\\n\\n'.format(scores_rnn,scores_lstm))\n",
        "print('Average CV Score- Deep RNN :{}\\n Average CV Score- Depp LSTM :{}\\n' .format(np.mean(scores_rnn),np.mean(scores_lstm) ))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDjsCTYPxFtA"
      },
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "    # plot history\n",
        "    plt.plot(history.history['loss'], label='train')\n",
        "    plt.plot(history.history['val_loss'], label='val')  \n",
        "    plt.xlabel('Epochs', fontsize=16)\n",
        "    plt.ylabel('Loss', fontsize=16)  \n",
        "    # plt.grid()\n",
        "    plt.legend(fontsize=20)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3z8PiaqjvW8"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1,2, sharey=True,figsize=(20,10))\n",
        "\n",
        "ax1.set_title(\"Deep RNN model\",fontsize=20)\n",
        "ax1.plot(history_rnn.history['loss'], label='train')\n",
        "ax1.plot(history_rnn.history['val_loss'], label='val')\n",
        "plt.legend(fontsize=20)\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=16)  \n",
        "\n",
        "ax2.set_title(\"Deep LSTM model\",fontsize=20)\n",
        "ax2.plot(history_lstm.history['loss'], label='train')\n",
        "ax2.plot(history_lstm.history['val_loss'], label='val')\n",
        "plt.legend(fontsize=20)\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=16)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjYxIjnwIduB"
      },
      "outputs": [],
      "source": [
        "fig = plt.subplots(figsize=(20,10))\n",
        "# fig.set_title(\"Loss\",fontsize=20)\n",
        "plt.plot(history_rnn.history['val_loss'], label='Deep RNN')\n",
        "plt.plot(history_lstm.history['val_loss'], label='Deep LSTM')\n",
        "plt.title(\"val Loss through epochs\",fontsize=20)\n",
        "plt.legend(fontsize=20)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyAxVLDqPtd5"
      },
      "outputs": [],
      "source": [
        "def prediction_persistence(test):\n",
        "\n",
        "  pred=pd.DataFrame(test.iloc[:,0])\n",
        "  pred['Predicted'] = last_train_value\n",
        "  pred['dt'] = test.index[-test.shape[0]:]\n",
        "  # Calculate the error \n",
        "  pred['Error'] = np.abs(pred['AverageTemperature'] - pred['Predicted'])\n",
        "  pred['APE']=pred['Error']/pred['AverageTemperature']*100\n",
        "\n",
        "  MAPE=np.mean(pred['APE'])\n",
        "  return pred,MAPE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boWCUw-T-AyL"
      },
      "source": [
        "Validation Score:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx0Tiu4eOnzY"
      },
      "outputs": [],
      "source": [
        "pred_base_line, MAPE_base_line=prediction_persistence(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_sBlIIM5Bp6"
      },
      "outputs": [],
      "source": [
        "val_rnn_score=np.mean(scores_rnn)\n",
        "val_lstm_score=np.mean(scores_lstm)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Of-Na1DybHI"
      },
      "outputs": [],
      "source": [
        "validation_score=pd.DataFrame()\n",
        "models=['Deep RNN','Deep LSTM','Naive-Baseline']\n",
        "validation_score['Models']=['Deep RNN','Deep LSTM','Naive-Baseline']\n",
        "scores=[val_rnn_score,val_lstm_score,(100-MAPE_base_line)] \n",
        "validation_score['validation_score']=[f\"{num:.1f}\" for num in scores]\n",
        "validation_score['validation_score']=validation_score['validation_score'].astype(float)\n",
        "\n",
        "validation_score.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6W9URL2VGANb"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "#  Bar plot\n",
        "plt.bar(validation_score['Models'], validation_score['validation_score'], color ='maroon',\n",
        "        width = 0.5)\n",
        "matplotlib.rcParams.update({'font.size': 16})\n",
        "for x,y in zip(validation_score['Models'], validation_score['validation_score']):\n",
        "\n",
        "    label = \"{:.2f}\".format(y)\n",
        "\n",
        "    plt.annotate(label, # this is the text\n",
        "                 (x,y), # these are the coordinates to position the label\n",
        "                 textcoords=\"offset points\", # how to position the text\n",
        "                 xytext=(0,10), # distance from text to points (x,y)\n",
        "                 ha='center') # horizontal alignment can be left, right or center\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Model Score\")\n",
        "plt.title(\"Model Score: 100-(Mean Absolute Percentage Error)\\n\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS3kPM32RTa1"
      },
      "source": [
        "#OPTUNA- Hyper Parameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxVl4XurRSwS"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "  hidden_units=trial.suggest_int(\"hidden_units\", 10, 100,step=10, log=False)\n",
        "  optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"SGD\", \"RMSprop\"])\n",
        "  epochs = trial.suggest_int(\"epochs\", 5, 40,step=5, log=False)\n",
        "  batchsize = trial.suggest_int(\"batchsize\", 1, 51,step=5, log=False)\n",
        "\n",
        "  scores_lstm = []\n",
        "  for sub_set,train_index, val_index in tscv.split(train_sc):\n",
        "    #LSTM\n",
        "    history_lstm,model_LSTM = create_LSTM_model(train_x_rs,val_x_rs,hidden_units=hidden_units,optimizer=optimizer,epochs=epochs,batchsize=batchsize)\n",
        "    val_lstm_per_fold=100-history_lstm.history['val_loss'][-1]\n",
        "    scores_lstm.append(val_lstm_per_fold)\n",
        "\n",
        "  val_mape=np.mean(scores_lstm)\n",
        "  # val_mape = model_LSTM.evaluate(val_x_rs,val_y)[1]\n",
        "  weights = model_LSTM.get_weights()\n",
        "\n",
        "  # Handle pruning based on the intermediate value.\n",
        "  if trial.should_prune():\n",
        "    raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "  trial.set_user_attr(key=\"best_model_weights\", value=weights)\n",
        "  return val_mape\n",
        "\n",
        "def callback(study, trial):\n",
        "    if study.best_trial.number == trial.number:\n",
        "        study.set_user_attr(key=\"best_model_weights\", \n",
        "                            value=trial.user_attrs[\"best_model_weights\"])\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50, timeout=None, callbacks=[callback])\n",
        "print(study.best_trial.value)  # Show the best value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtXX3honMo49"
      },
      "outputs": [],
      "source": [
        "study.best_trial.value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDifscmjNgV7"
      },
      "outputs": [],
      "source": [
        "study.best_trial.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwMm8NdJUcjB"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bPTy8u-xFbk"
      },
      "outputs": [],
      "source": [
        "hidden_units=80\n",
        "optimizer='RMSprop'\n",
        "epochs=100\n",
        "batchsize=26\n",
        "\n",
        "# {'batchsize': 26, 'epochs': 30, 'hidden_units': 80, 'optimizer': 'RMSprop'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2cK3piKxCT0"
      },
      "outputs": [],
      "source": [
        "scores_shallow_rnn=[]\n",
        "scores_rnn = []\n",
        "scores_lstm = []\n",
        "\n",
        "#get the block-time-series single fold indices\n",
        "for sub_set,train_index, val_index in tscv.split(train_sc):\n",
        "  # print(\"\\n\\nsub_set:\", sub_set,\"\\nTRAIN:\\n\", train_index, \"\\nval:\\n\", val_index)\n",
        "\n",
        "  #subset the scaled train set into rtain and validation according to indeices we got from the prev. step\n",
        "  train_x = train_sc[train_index,:-1]\n",
        "  val_x = train_sc[val_index,:-1]\n",
        "  train_y = train_sc[train_index,-1]\n",
        "  val_y = train_sc[val_index,-1]\n",
        "  print (train_x.shape[0],1,train_x.shape[1])\n",
        "  print (val_x.shape[0],1,val_x.shape[1])\n",
        "\n",
        "  # #reshape: (sample size,time_stamp (see explanation above), features)\n",
        "  train_x_rs=train_x.reshape(train_x.shape[0],1,train_x.shape[1])\n",
        "  val_x_rs=val_x.reshape(val_x.shape[0],1,val_x.shape[1])\n",
        "  \n",
        "\n",
        "  #get the block-time-series single fold indices\n",
        "for sub_set,train_index, val_index in tscv.split(train_sc):\n",
        " \n",
        "  #RNN\n",
        "  history_rnn,model_RNN = create_RNN_model(train_x_rs,val_x_rs,hidden_units=hidden_units,optimizer=optimizer,epochs=epochs,batchsize=batchsize)\n",
        "  val_rnn_score=100-history_rnn.history['val_loss'][-1]\n",
        "  # print('MAPE DEEP RNN:  ',history_rnn.history['val_loss'][-1])\n",
        "  scores_rnn.append(val_rnn_score)\n",
        "\n",
        "  #LSTM\n",
        "  history_lstm,model_LSTM = create_LSTM_model(train_x_rs,val_x_rs,hidden_units=hidden_units,optimizer=optimizer,epochs=epochs,batchsize=batchsize)\n",
        "  # print('MAPE DEEP LSTM:  ',history_lstm.history['val_loss'][-1])\n",
        "  val_lstm_score=100-history_lstm.history['val_loss'][-1]\n",
        "  scores_lstm.append(val_lstm_score)\n",
        "\n",
        "print('Scores from each Iteration- Deep RNN: {}\\n Scores from each Iteration- Deep LSTM: {}\\n\\n'.format(scores_rnn,scores_lstm))\n",
        "print('Average CV Score- Deep RNN :{}\\n Average CV Score- Depp LSTM :{}\\n' .format(np.mean(scores_rnn),np.mean(scores_lstm)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaczgmPGYe9B"
      },
      "source": [
        "Validation Score sfter OPTUNA:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_602MYv_wjQs"
      },
      "outputs": [],
      "source": [
        "val_rnn_score=np.mean(scores_rnn)\n",
        "val_lstm_score=np.mean(scores_lstm)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRebZk37wjQx"
      },
      "outputs": [],
      "source": [
        "validation_score=pd.DataFrame()\n",
        "models=['Deep RNN','Deep LSTM', 'Naive-Baseline',]\n",
        "validation_score['Models']=['Deep RNN','Deep LSTM','Naive-Baseline',]\n",
        "scores=[val_rnn_score,val_lstm_score,(100-MAPE_base_line)] \n",
        "validation_score['validation_score']=[f\"{num:.1f}\" for num in scores]\n",
        "validation_score['validation_score']=validation_score['validation_score'].astype(float)\n",
        "\n",
        "validation_score.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD9yu1erwjQy"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "#  Bar plot\n",
        "plt.bar(validation_score['Models'], validation_score['validation_score'], color ='maroon',\n",
        "        width = 0.5)\n",
        "matplotlib.rcParams.update({'font.size': 16})\n",
        "for x,y in zip(validation_score['Models'], validation_score['validation_score']):\n",
        "\n",
        "    label = \"{:.2f}\".format(y)\n",
        "\n",
        "    plt.annotate(label, # this is the text\n",
        "                 (x,y), # these are the coordinates to position the label\n",
        "                 textcoords=\"offset points\", # how to position the text\n",
        "                 xytext=(0,10), # distance from text to points (x,y)\n",
        "                 ha='center') # horizontal alignment can be left, right or center\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Model Score\")\n",
        "plt.title(\"Model Score After Hyper Parameter tuning:\\n100-(Mean Absolute Percentage Error)\\n\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfUgyYhcRxat"
      },
      "source": [
        "#Prediction on Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbuPqKUfAwaU"
      },
      "source": [
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Odu073FMfGxw"
      },
      "outputs": [],
      "source": [
        "def unified_train_and_val(train,train_x,train_y,val,val_x,val_y):\n",
        "  train=np.concatenate((train,val),axis=0)\n",
        "  train_x=np.concatenate((train_x,val_x))\n",
        "  train_y=np.concatenate((train_y,val_y))\n",
        "  # train=np.concatenate((train,val),axis=0)\n",
        "  # train_x=np.concatenate((train_x,val_x),axis=0)\n",
        "  # train_y=np.concatenate((train_y,val_y),axis=0)\n",
        "\n",
        "\n",
        "  return train,train_x,train_y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-W4-h7IAbOq"
      },
      "outputs": [],
      "source": [
        "to_initial_test_row=train.iloc[-1] #train_unified[-1]\n",
        "to_initial_test_row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77JYJaSF3mT4"
      },
      "outputs": [],
      "source": [
        "#Create frame to test data:\n",
        "test = prepare_data(test, num_of_lag_differences)\n",
        "test=test.drop(['AverageTemperature'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BVgCDtek9KY"
      },
      "outputs": [],
      "source": [
        "def Auto_regressive_prediction(model,test):\n",
        "  test_y=test.iloc[:,-1]\n",
        "  test_x_ff=test.iloc[0,]\n",
        "\n",
        "  columns=[test_x_ff.index]\n",
        "  index=2\n",
        "\n",
        "  #create prediction data set. i will fill this set sample after sample while i'll base my prediction calculaion on prev. predicted temperature\n",
        "\n",
        "\n",
        "  '''                                          FIRST TEST RECORD\n",
        "                                            -----------------------'''\n",
        "  #fill first row based on known train data\n",
        "  for i in range(2,len(test_x_ff)-1):\n",
        "    test_x_ff[i]=to_initial_test_row[index+1]\n",
        "    index=index+1\n",
        "  print(\"new test_x:\",test_x_ff)\n",
        "  sample= test_x_ff.to_numpy().reshape(1,-1)\n",
        "  sample=scaler.transform(sample)\n",
        "  x=sample[:,:-1]\n",
        "  sample_rss=x.reshape(1,1,14) #reshape to fit RNN prediction\n",
        "\n",
        "  #predict of the 1st sample:\n",
        "  perdict_first=model.predict(sample_rss)\n",
        "  print(perdict_first)\n",
        "  print(perdict_first.shape)\n",
        "\n",
        "  # Reshape sample for inverse transform and visualization\n",
        "  sample = sample_rss.copy().reshape((sample_rss.shape[0], sample_rss.shape[2]))\n",
        "  test_new=np.append(sample,perdict_first, axis=1) ##add the prediction before inverse transform\n",
        "  test_new= scaler.inverse_transform(test_new)\n",
        "  test_new=pd.DataFrame(test_new,columns=columns)\n",
        "  test_new=test_new.rename(columns={'Target': 'Prediction'})\n",
        "  columns=[test_new.columns.get_level_values(0)] #need to flat the columns because for some reason it appeared to be MultiIndex which cause a problem to append later with new samples\n",
        "\n",
        "\n",
        "  '''                                           ALL OTHER RECORDS\n",
        "                                            -----------------------'''\n",
        "  remain_test=test.iloc[1:,:]\n",
        "  for i in range(len(remain_test)):\n",
        "    sample=remain_test.iloc[i,:]\n",
        "    for column in range (2,len(sample)-1):\n",
        "      sample[column]=test_new.iloc[-1,column+1]\n",
        "    sample= sample.to_numpy().reshape(1,-1)\n",
        "    sample=scaler.transform(sample)\n",
        "    x=sample[:,:-1]\n",
        "    sample_rss=x.reshape(1,1,14) #reshape to fit RNN prediction\n",
        "    perdict=model.predict(sample_rss)\n",
        "\n",
        "    # Reshape sample for inverse transform and visualization\n",
        "    sample = sample_rss.copy().reshape((sample_rss.shape[0], sample_rss.shape[2]))\n",
        "    new=np.append(sample,perdict, axis=1) ##add the prediction before inverse transform\n",
        "    new= scaler.inverse_transform(new)\n",
        "\n",
        "    df1 = pd.DataFrame(new,columns=columns,index=[i+1])\n",
        "    test_new=pd.concat([test_new, df1])\n",
        "\n",
        "  pred = pd.DataFrame()\n",
        "  pred['Original'] = test_y.values\n",
        "  pred['Predicted'] = test_new.iloc[:,-1]\n",
        "  pred['dt'] = test.index[-test.shape[0]:]\n",
        "  # Calculate the error \n",
        "  pred['Error'] = np.abs(pred['Original'] - pred['Predicted'])\n",
        "  pred['APE']=(pred['Error']/pred['Original'])*100\n",
        "\n",
        "  MAPE=np.mean(pred['APE'])\n",
        "  return pred,MAPE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zl4w0KiL34EN"
      },
      "outputs": [],
      "source": [
        "pred_rnn, MAPE_rnn = Auto_regressive_prediction(model_RNN,test)\n",
        "pred_lstm, MAPE_lstm = Auto_regressive_prediction(model_LSTM,test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JfD018lpA53"
      },
      "outputs": [],
      "source": [
        "def plot_prediction(df1,title1,df2,title2,df3,title3,x_axes='Date'):#,df4,title4\n",
        "  from plotly.subplots import make_subplots\n",
        "  fig = make_subplots(rows=1, cols=2,subplot_titles=('Prediction vs. Actual: ','Mean Absolute Precentage Error: '))\n",
        "\n",
        "  if 'dt' in df1.columns:\n",
        "    x = df1['dt']\n",
        "  else:\n",
        "    x = df1.index\n",
        "  fig.add_scatter(x = x, y = df1['Original'], name = 'Original', row=1, col=1,mode='lines+markers', line=dict(color=\"black\"),legendgroup = '1')\n",
        "  fig.add_scatter(x = x, y = df1['Predicted'], name = 'Predicted: '+title1, row=1, col=1,opacity = 0.5,mode='lines+markers', line=dict(color='purple'),legendgroup = '1')\n",
        "  fig.add_scatter(x = x, y = df2['Predicted'], name = 'Predicted: '+title2, row=1, col=1,mode='lines+markers', line=dict(color='blue'),legendgroup = '1')\n",
        "  fig.add_scatter(x = x, y = df3['Predicted'], name = 'Predicted: '+title3, row=1, col=1,opacity = 0.5,mode='lines+markers', line=dict(color=\"orange\"),legendgroup = '1')\n",
        "  # fig.add_scatter(x = x, y = df4['Predicted'], name = 'Predicted: '+title4, row=1, col=1,opacity = 0.5,mode='lines+markers', line=dict(color=\"pink\"),legendgroup = '1')\n",
        "\n",
        "\n",
        "  fig.add_scatter(x = x, y = df1['APE'], name = 'MAPE-'+title1, opacity = 0.5,row=1, col=2,mode='lines+markers', line=dict(color='purple'),legendgroup = '2')\n",
        "  fig.add_scatter(x = x, y = df2['APE'], name = 'MAPE-'+title2, row=1, col=2,mode='lines+markers', line=dict(color='blue'),legendgroup = '2')\n",
        "  fig.add_scatter(x = x, y = df3['APE'], name = 'MAPE-'+title3, opacity = 0.5,row=1, col=2,mode='lines+markers', line=dict(color=\"orange\"),legendgroup = '2')\n",
        "  # fig.add_scatter(x = x, y = df4['APE'], name = 'MAPE-'+title4, opacity = 0.5,row=1, col=2,mode='lines+markers', line=dict(color=\"pink\"),legendgroup = '2')\n",
        "\n",
        "\n",
        "  fig.update_xaxes(title_text=x_axes)\n",
        "  fig.update_layout(height=500,legend_tracegroupgap = 180)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6YReE4_pA53"
      },
      "source": [
        "# ASSESS MODEL PERFORMANCE (GLOBAL DATA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLM5lMBJQKXJ"
      },
      "outputs": [],
      "source": [
        "test_score=pd.DataFrame()\n",
        "models=['Deep RNN','Deep LSTM','Naive-Baseline']\n",
        "test_score['Models']=['Deep RNN','Deep LSTM','Naive-Baseline']\n",
        "scores=[(100-MAPE_rnn),(100-MAPE_lstm),(100-MAPE_base_line)]\n",
        "test_score['test_score']=[f\"{num:.1f}\" for num in scores]\n",
        "test_score['test_score']=test_score['test_score'].astype(float)\n",
        "test_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvIUsjdpQ8lB"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (10, 5))\n",
        "#  Bar plot\n",
        "plt.bar(test_score['Models'], test_score['test_score'], color ='blue',\n",
        "        width = 0.5)\n",
        "matplotlib.rcParams.update({'font.size': 16})\n",
        "\n",
        "for x,y in zip(test_score['Models'], test_score['test_score']):\n",
        "\n",
        "    label = \"{:.2f}\".format(y)\n",
        "\n",
        "    plt.annotate(label, # this is the text\n",
        "                 (x,y), # these are the coordinates to position the label\n",
        "                 textcoords=\"offset points\", # how to position the text\n",
        "                 xytext=(0,10), # distance from text to points (x,y)\n",
        "                 ha='center') # horizontal alignment can be left, right or center\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Model Score\")\n",
        "plt.title(\"Final Model Score- test set: 100-(Mean Absolute Percentage Error)\\n\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC7pDKcVb1hi"
      },
      "outputs": [],
      "source": [
        "print('MAPE DEEP RNN:',MAPE_rnn)\n",
        "print('MAPE DEEP LSTM:',MAPE_lstm)\n",
        "print('MAPE base_line:',MAPE_base_line)\n",
        "# print('MAPE Random Forest:',MAPE_rf)\n",
        "print('\\n\\nAccuracy RNN:',100-MAPE_rnn)\n",
        "print('Accuracy LSTM:',100-MAPE_lstm)\n",
        "print('Accuracy base_line:',100-MAPE_base_line)\n",
        "# print('Accuracy Random Forest:',100-MAPE_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LCuIj_4nKUd"
      },
      "outputs": [],
      "source": [
        "def PredictionGrouedby_MonthYear(df):\n",
        "  #year:\n",
        "  df['Year']=df['dt'].apply(lambda x: x.split('-')[0])\n",
        "  df['Year']=df['Year'].astype(int)\n",
        "\n",
        "  #month:\n",
        "  df['Month']=df['dt'].apply(lambda x: x.split('-')[1])\n",
        "  df['Month']=df['Month'].astype(int)\n",
        "\n",
        "  prediction_per_year=df.groupby(['Year']).mean()\n",
        "  prediction_per_year=prediction_per_year.drop(['Month'],axis=1)\n",
        "\n",
        "\n",
        "  prediction_per_month=df.groupby(['Month']).mean()\n",
        "  prediction_per_month=prediction_per_month.drop(['Year'],axis=1)\n",
        "  print(prediction_per_month)\n",
        "\n",
        "  return prediction_per_year,prediction_per_month\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzS_ZSBdm1nK"
      },
      "outputs": [],
      "source": [
        "pred_rnn_by_year,pred_rnn_by_month=PredictionGrouedby_MonthYear(pred_rnn)\n",
        "pred_lstm_by_year,pred_lstm_by_month=PredictionGrouedby_MonthYear(pred_lstm)\n",
        "pred_base_line_by_year,pred_base_line_by_month=PredictionGrouedby_MonthYear(pred_base_line)\n",
        "# pred_rf_by_year,pred_rf_by_month=PredictionGrouedby_MonthYear(pred_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdH9kDJaSgZ1"
      },
      "outputs": [],
      "source": [
        "pred_rnn_by_month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTcqaHi30dxT"
      },
      "outputs": [],
      "source": [
        "print('MAPE-RNN model: ',MAPE_rnn,'\\nMAPE-LSTM model: ',MAPE_lstm,'\\nMAPE-Base-Line- Persistence model ',MAPE_base_line)\n",
        "plot_prediction(pred_rnn_by_year,\"RNN model\",pred_lstm_by_year,\"LSTM model\",pred_base_line_by_year,\"Base-Line- Persistence model\",x_axes='Year') #,pred_rf_by_year,\"RF model\"\n",
        "plot_prediction(pred_rnn_by_month,\"RNN model\",pred_lstm_by_month,\"LSTM model\",pred_base_line_by_month,\"Base-Line- Persistence model:\",x_axes='Month') #,pred_rf_by_month,\"RF model\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXT1SdORimYV"
      },
      "outputs": [],
      "source": [
        "fig = make_subplots(rows=1, cols=1,subplot_titles=('Mean Absolute Precentage Error: '))\n",
        "if 'dt' in pred_rnn.columns:\n",
        "  x = pred_rnn['dt']\n",
        "else:\n",
        "  x = pred_rnn.index\n",
        "# fig.add_scatter(x = x, y = pred_rnn['Original'], name = 'Original', row=1, col=2,mode='lines+markers', line=dict(color=\"black\"),legendgroup = '1')\n",
        "# fig.add_scatter(x = x, y = pred_rnn['Predicted'], name = 'Predicted- RNN: ', row=1, col=2,opacity = 0.5,mode='lines+markers', line=dict(color='purple'),legendgroup = '1')\n",
        "# fig.add_scatter(x = x, y = pred_lstm['Predicted'], name = 'Predicted-LSTM ', row=1, col=2,mode='lines+markers', line=dict(color='blue'),legendgroup = '1')\n",
        "# fig.add_scatter(x = x, y = pred_base_line['Predicted'], name = 'Predicted-Base-Line- Persistence model ', row=1, col=2,opacity = 0.5,mode='lines+markers', line=dict(color=\"orange\"),legendgroup = '1')\n",
        "# fig.add_scatter(x = x, y = pred_rf['Predicted'], name = 'Predicted-Base-Line- Persistence model ', row=1, col=2,opacity = 0.5,mode='lines+markers', line=dict(color=\"pink\"),legendgroup = '1')\n",
        "\n",
        "fig.add_scatter(x = x, y = pred_base_line['APE'], name = 'MAPE-Base-Line- Persistence model', opacity = 0.5,row=1, col=1,mode='lines+markers', line=dict(color=\"orange\"),legendgroup = '2')\n",
        "# fig.add_scatter(x = x, y = pred_rf['APE'], name = 'MAPE-Base-Line- RF',row=1, col=1,mode='lines+markers', line=dict(color=\"red\"),legendgroup = '2')\n",
        "fig.add_scatter(x = x, y = pred_rnn['APE'], name = 'MAPE-RNN', row=1, col=1,mode='lines+markers', line=dict(color='purple'),legendgroup = '2')\n",
        "fig.add_scatter(x = x, y = pred_lstm['APE'], name = 'MAPE- LSTM', row=1, col=1,mode='lines+markers', line=dict(color='blue'),legendgroup = '2')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fig.update_layout(height=700,legend_tracegroupgap = 180)\n",
        "fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HLkdRkWSP40"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Final-Tempreture Change Forecasting .ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
